---
---

@Article{Jalali2024rank,
  author={Mohammad Jalali and Ramin Javadi},
  title={Maximizing Rank Agreement Under Noisy Comparisons},
  year={2024},
  journal={Under Review},
  abstract={In this paper, we investigate the problem of ranking with maximum agreement under noisy comparisons. The input is a collection of pairwise comparisons between the elements of a ground set derived from a hidden embedded ranking which are exposed to an external noise and so may have inconsistencies. The goal is to reconstruct the ground truth with minimum error or maximize the number of satisfied comparisons. We propose three algorithms called In-Degree, PageRank, and Hybrid for solving this problem. We analyze our algorithms under a stochastic model which is a refinement of Erd\H{o}s-R\'{e}nyi model and each pairwise comparison is revealed independently with probability $p$ and each revealed comparison is reversed with probability $\epsilon$ (noise rate). For the In-degree algorithm, we give a theoretical bound for the error rate of the obtained ranking in comparison with the ground truth. In particular we prove that when $n$ is the number of items and $p=\alpha \ln n /n$, for some constant $\alpha$, then the error rate is at most $O({\alpha}^{-1/3}{(1-\epsilon)^{2/3}}/(1-2\epsilon))$. We also compare the performance of our algorithms with previous known methods in several experiments with synthetic and real data.},
  selected={false},
  abbr={Under Rev.},
}

@inproceedings{Jalali2023rke,
  author={Mohammad Jalali and Cheuk Ting Li and Farzan Farnia},
  title={An Information-Theoretic Evaluation of Generative Models in Learning Multi-modal Distributions},
  year={2023},
  booktitle={37th conference on Neural Information Processing Systems (NeurIPS)},
  abstract={The evaluation of generative models has received significant attention in the machine learning community. When applied to a multi-modal distribution which is common among image datasets, an intuitive evaluation criterion is the number of modes captured by the generative model. While several scores have been proposed to evaluate the quality and diversity of a model's generated data, the correspondence between existing scores and the number of modes in the distribution is unclear. In this work, we propose an information-theoretic diversity evaluation method for multi-modal underlying distributions. We utilize the R'enyi Kernel Entropy (RKE) as an evaluation score based on quantum information theory to measure the number of modes in generated samples. To interpret the proposed evaluation method, we show that the RKE score can output the number of modes of a mixture of sub-Gaussian components. We also prove estimation error bounds for estimating the RKE score from limited data, suggesting a fast convergence of the empirical RKE score to the score for the underlying data distribution. Utilizing the RKE score, we conduct an extensive evaluation of state-of-the-art generative models over standard image datasets. The numerical results indicate that while the recent algorithms for training generative models manage to improve the mode-based diversity over the earlier architectures, they remain incapable of capturing the full diversity of real data. Our empirical results provide a ranking of widely-used generative models based on the RKE score of their generated samples.},
  selected={true},
  url={https://openreview.net/forum?id=PdZhf6PiAb},
  pdf={https://openreview.net/pdf?id=PdZhf6PiAb},
  supp={https://openreview.net/attachment?id=PdZhf6PiAb&name=supplementary_material},
  code={https://github.com/mjalali/renyi-kernel-entropy},
  poster={NeurIPS23Poster_rke.pdf},
  bibtex_show={true},
  abbr={NeurIPS 2023},
  preview={evaluation.png},
}

@Article{MohebbiMoghaddam2023,
  author={Mohebbi Moghaddam, Monireh
  and Boroomand*, Bahar
  and Jalali*, Mohammad
  and Zareian*, Arman
  and Daeijavad, Alireza
  and Manshaei, Mohammad Hossein
  and Krunz, Marwan},
  title={Games of GANs: game-theoretical models for generative adversarial networks},
  journal={Artificial Intelligence Review},
  year={2023},
  month={Feb},
  day={13},
  abstract={Generative Adversarial Networks (GANs) have recently attracted considerable attention in the AI community due to their ability to generate high-quality data of significant statistical resemblance to real data. Fundamentally, GAN is a game between two neural networks trained in an adversarial manner to reach a zero-sum Nash equilibrium profile. Despite the improvement accomplished in GANs in the last few years, several issues remain to be solved. This paper reviews the literature on the game-theoretic aspects of GANs and addresses how game theory models can address specific challenges of generative models and improve the GAN's performance. We first present some preliminaries, including the basic GAN model and some game theory background. We then present aÂ taxonomy to classify state-of-the-art solutions into three main categories: modified game models, modified architectures, and modified learning methods. The classification is based on modifications made to the basic GAN model by proposed game-theoretic approaches in the literature. We then explore the objectives of each category and discuss recent works in each class. Finally, we discuss the remaining challenges in this field and present future research directions.},
  issn={1573-7462},
  doi={10.1007/s10462-023-10395-6},
  url={https://doi.org/10.1007/s10462-023-10395-6},
  selected={true},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2106.06976.pdf},
  abbr={Artif Intell Rev},
  preview={game-of-gans.png},
}

@article{MohebbiMoghaddamArXiv2021,
  author    = {Monireh Mohebbi Moghadam and
               Bahar Boroumand* and
               Mohammad Jalali* and
               Arman Zareian* and
               Alireza Daei Javad and
               Mohammad Hossein Manshaei},
  title     = {Game of GANs: Game Theoretical Models for Generative Adversarial Networks},
  journal   = {arXiv preprint arXiv:2106.06976},
  volume    = {abs/2106.06976},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06976},
  eprint    = {2106.06976},
  abstract={Generative Adversarial Networks (GANs) have recently attracted considerable attention in the AI community due to its ability to generate high-quality data of significant statistical resemblance to real data. Fundamentally, GAN is a game between two neural networks trained in an adversarial manner to reach a zero-sum Nash equilibrium profile. Despite the improvement accomplished in GANs in the last few years, several issues remain to be solved. This paper reviews the literature on the game theoretic aspects of GANs and addresses how game theory models can address specific challenges of generative model and improve the GAN's performance. We first present some preliminaries, including the basic GAN model and some game theory background. We then present taxonomy to classify state-of-the-art solutions into three main categories: modified game models, modified architectures, and modified learning methods. The classification is based on modifications made to the basic GAN model by proposed game-theoretic approaches in the literature. We then explore the objectives of each category and discuss recent works in each category. Finally, we discuss the remaining challenges in this field and present future research directions.},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2106.06976.pdf},
  abbr={arXiv},
  arxiv={2106.06976},
  preview={game-of-gans.png},
}
